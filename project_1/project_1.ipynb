{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colormaps\n",
    "from matplotlib import colormaps\n",
    "from ipywidgets import interact, widgets\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Standard Asset Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# First read all excel sheets\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m market_cap_daily \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGroup_G.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, sheet_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      3\u001B[0m price_index_daily \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGroup_G.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, sheet_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      4\u001B[0m revenue_monthly \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_excel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGroup_G.xlsx\u001B[39m\u001B[38;5;124m'\u001B[39m, sheet_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, index_col\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDate\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# First read all excel sheets\n",
    "market_cap_daily = pd.read_excel('Group_G.xlsx', sheet_name=1, index_col='Date')\n",
    "price_index_daily = pd.read_excel('Group_G.xlsx', sheet_name=2, index_col='Date')\n",
    "revenue_monthly = pd.read_excel('Group_G.xlsx', sheet_name=3, index_col='Date')\n",
    "emission_monthly = pd.read_excel('Group_G.xlsx', sheet_name=4, index_col='Date')\n",
    "\n",
    "\n",
    "# # Reformat the column name\n",
    "market_cap_daily.columns = ['_'.join(i.split('-')[0].split(' ')[:-1]) for i in market_cap_daily.keys()]\n",
    "price_index_daily.columns = ['_'.join(i.split('-')[0].split(' ')[:-1]) for i in price_index_daily.keys()]\n",
    "# revenue_monthly.columns = ['_'.join(i.split('-')[0].split(' ')[:2]) for i in revenue_monthly.keys()]\n",
    "emission_monthly.columns = ['_'.join(i.split('-')[0].split(' ')[:-1]) for i in emission_monthly.keys()]\n",
    "\n",
    "\n",
    "# Using the data from the last day of the month for market cap and price index\n",
    "price_index_monthly = price_index_daily.resample('M').last()\n",
    "market_cap_monthy = market_cap_daily.resample('M').last()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Describe the characteristics of the stocks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get simple and log returns\n",
    "def assets_returns(assets, period, compounded=True):\n",
    "    if not compounded:\n",
    "        asset_return = (assets / assets.shift(periods=period)) - 1\n",
    "    else:\n",
    "        diff = assets / assets.shift(periods=period)\n",
    "        asset_return = np.log(diff.astype('float'))\n",
    "    return asset_return\n",
    "\n",
    "\n",
    "# Get moments of returns\n",
    "def get_moment(asset_return, moment):\n",
    "    if moment == 1:\n",
    "        return pd.DataFrame(asset_return.mean())\n",
    "    elif moment == 2:\n",
    "        return pd.DataFrame(asset_return.std())\n",
    "    elif moment == 3:\n",
    "        return pd.DataFrame(asset_return.skew())\n",
    "    elif moment == 4:\n",
    "        nu = (pow(asset_return, moment)).mean() - pow(asset_return.mean(), moment)\n",
    "        den = pow(asset_return.std(), moment)\n",
    "        res = nu / den\n",
    "        return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Returns \n",
    "\n",
    "# Simple return \n",
    "simple_return = assets_returns(\n",
    "    price_index_monthly,\n",
    "    period=1,\n",
    "    compounded=False  # not compounded\n",
    ")\n",
    "\n",
    "# Log return \n",
    "log_return = assets_returns(\n",
    "    price_index_monthly,\n",
    "    period=1,\n",
    "    compounded=True  # compounded\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test for distribution of stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test for the distribution of stocks and subsequently using MLE to estimate the in-sample mean, we have the following steps:\n",
    "\n",
    "1. Use rolling window to get sample moments by year \n",
    "2. Use Jarque Bera to test for the normality of returns \n",
    "3. Use Smirnov to test for distribution of data \n",
    "4. Use MLE to estimate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43msns\u001B[49m\u001B[38;5;241m.\u001B[39mdisplot(log_return\u001B[38;5;241m.\u001B[39miloc[:,\u001B[38;5;241m1\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.displot(log_return.iloc[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Build the efficient frontier using sample mean and sample covariance matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Use resampling to determine optimal weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
